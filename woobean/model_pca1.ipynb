{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### module import \n",
    "import pandas as pd \n",
    "import numpy as np \n",
    "import matplotlib.pyplot as plt\n",
    "# import seaborn as sns\n",
    "# Suppress Deprecation and Incorrect Usage Warnings \n",
    "import warnings\n",
    "import scipy.io as sio \n",
    "import os\n",
    "import scipy.signal as signal\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, Normalizer , MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "warnings.filterwarnings('ignore')\n",
    "import copy\n",
    "import scipy.signal as signal\n",
    "import scipy.stats as stats\n",
    "import scipy.io as sio\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('./data/1.0.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 2400)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([14.66085519, 14.65925504, 14.64617424, ..., 14.18128998,\n",
       "       14.18512493, 14.20130588])"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1.08278797e-05, 5.53920174e-06, 2.29579565e-06, ...,\n",
       "        5.24512813e-08, 4.68298894e-07, 3.39861850e-07],\n",
       "       [3.57938324e-05, 4.82053202e-05, 1.87760579e-07, ...,\n",
       "        3.52065664e-04, 1.30183380e-04, 3.60864259e-04],\n",
       "       [7.26301702e-05, 2.06384163e-04, 2.00519167e-05, ...,\n",
       "        1.08884221e-03, 4.47711797e-04, 1.11777081e-03],\n",
       "       ...,\n",
       "       [1.79993368e-08, 1.76072544e-07, 1.20783217e-07, ...,\n",
       "        7.49058838e-08, 2.71896835e-08, 1.36127625e-08],\n",
       "       [5.34422544e-08, 2.48106291e-07, 8.28063885e-08, ...,\n",
       "        4.46004132e-08, 4.71601249e-08, 6.88080692e-09],\n",
       "       [3.57734101e-08, 1.38451283e-07, 3.18002008e-08, ...,\n",
       "        1.33314176e-08, 2.77322118e-08, 2.99547607e-09]])"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_,_, spec_data = signal.spectrogram(data[0,:],fs=1200,nperseg=256,noverlap=128,nfft=1024)\n",
    "spec_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "(129, 74) 3.0\n"
     ]
    }
   ],
   "source": [
    "data_set = np.load(f'./pca1_data/{0}.0.npy')\n",
    "_,_, spec_data1 = signal.spectrogram(data_set[0,:],fs=1200,nperseg=64,noverlap=32,nfft=256)\n",
    "\n",
    "spec_data1 = spec_data1[:240,:]\n",
    "data = spec_data1\n",
    "target = data_set[1][0]\n",
    "print(data.shape,target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<__main__.Dataset at 0x7fd9bec7cc10>"
      ]
     },
     "metadata": {},
     "execution_count": 21
    }
   ],
   "source": [
    "import copy\n",
    "import scipy.signal as signal\n",
    "import scipy.stats as stats\n",
    "import scipy.io as sio\n",
    "import tqdm\n",
    "from torch.utils.data import Dataset\n",
    "\n",
    "class Dataset(Dataset):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        if self.path[-1] != '/':\n",
    "            self.path += '/'        \n",
    "        self.NFFF = 240\n",
    "\n",
    "    def __len__(self):\n",
    "        return 179\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        data_set = np.load(f'{self.path}{idx}.0.npy')\n",
    "        _,_, spec_data1 = signal.spectrogram(data_set[0,:],fs=1200,nperseg=64,noverlap=32,nfft=256)\n",
    "\n",
    "        spec_data1 = spec_data1[:self.NFFF,:]\n",
    "        data = spec_data1\n",
    "        target = data_set[1][0]\n",
    "\n",
    "        return data,target\n",
    "Dataset('./pca1_data/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self,NFILT=3,NOUT=4):\n",
    "        super(NN,self).__init__()\n",
    "        self.conv0 = nn.Conv2d(4,NFILT, kernel_size=(2,2))\n",
    "        # self.conv0 = nn.Conv2d(1,NFILT,kernel_size=(200,3),padding=(0,1),bias=False)\n",
    "        # self.bn0 = nn.BatchNorm2d(NFILT)\n",
    "        self.gru = nn.GRU(input_size=NFILT,hidden_size=4,num_layers=1,batch_first=True,bidirectional=False)\n",
    "        self.fc1 = nn.Linear(3,NOUT)\n",
    "\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv0(x))\n",
    "        # x = x.squeeze().permute(0,2,1)\n",
    "        x,_ = self.gru(x)\n",
    "        x = F.dropout(x,p=0.5,training=self.training)\n",
    "        x = self.fc1(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "NameError",
     "evalue": "name 'DEVICE' is not defined",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-fcdd42900e97>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     68\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m             \u001b[0mt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDEVICE\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlong\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'DEVICE' is not defined"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "class NN(nn.Module):\n",
    "    def __init__(self,NFILT=32,NOUT=4):\n",
    "        super(NN,self).__init__()\n",
    "        self.h1 = nn.Linear(4, NFILT)\n",
    "        # self.h2 = nn.Linear(NFILT, 10)\n",
    "        self.out = nn.Linear(NFILT,NOUT)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.h1(x))\n",
    "        # x = F.relu(self.h2(x))\n",
    "        # x = nn.Linear(32, )\n",
    "        x = self.out(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data.dataset import random_split\n",
    "\n",
    "epochs = 5\n",
    "lr = 0.01\n",
    "momentum = 0.5\n",
    "log_interval = 200\n",
    "seed = 1\n",
    "torch.manual_seed(seed)\n",
    "\n",
    "# create training and validation dataset\n",
    "dataset_train, dataset_valid = random_split(Dataset('./pca1_data/'), [149,30], generator=torch.Generator().manual_seed(42))\n",
    "dataset_train, dataset_test = random_split(dataset_train, [121,28], generator=torch.Generator().manual_seed(42))\n",
    "NWORKERS = 24\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "TRAIN = DataLoader(dataset=dataset_train,\n",
    "                   batch_size=3,\n",
    "                   shuffle=True,\n",
    "                   drop_last=False,\n",
    "                   num_workers=NWORKERS)\n",
    "\n",
    "TEST = DataLoader(dataset=dataset_test,\n",
    "                   batch_size=3,\n",
    "                   shuffle=True,\n",
    "                   drop_last=False,\n",
    "                   num_workers=NWORKERS)\n",
    "\n",
    "VALID = DataLoader(dataset=dataset_valid,\n",
    "                   batch_size=3,\n",
    "                   shuffle=True,\n",
    "                   drop_last=False,\n",
    "                   num_workers=NWORKERS)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    model = NN().to(device)\n",
    "    optimizer = optim.Adam(model.parameters(),lr=1e-3,weight_decay=1e-4)\n",
    "    loss = nn.CrossEntropyLoss()\n",
    "\n",
    "    for epoch in range(2):\n",
    "        model.train()\n",
    "        for i,(x,t) in enumerate(TRAIN):\n",
    "            optimizer.zero_grad()\n",
    "            x = x.to(device).float()\n",
    "            t = t.to(device).long()\n",
    "            y = model(x)\n",
    "            J = loss(input=y,target=t)\n",
    "            J.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            if i%50==0:\n",
    "                print('EPOCH:{}\\tITER:{}\\tLOSS:{}'.format(str(epoch).zfill(2),\n",
    "                                                          str(i).zfill(5),\n",
    "                                                          J.data.cpu().numpy()))\n",
    "\n",
    "        # evaluate results for validation test\n",
    "        model.eval()\n",
    "        for i,(x,t) in enumerate(VALID):\n",
    "            x = x.to(device).float()\n",
    "            t = t.to(device).long()\n",
    "            y = model(x)\n",
    "            \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create training and validation dataset\n",
    "dataset_train, dataset_valid = random_split(Dataset('./data/'), [149,30], generator=torch.Generator().manual_seed(42))\n",
    "dataset_train, dataset_test = random_split(dataset_train, [121,28], generator=torch.Generator().manual_seed(42))\n",
    "NWORKERS = 24\n",
    "DEVICE = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "TRAIN = DataLoader(dataset=dataset_train,\n",
    "                   batch_size=32,\n",
    "                   shuffle=True,\n",
    "                   drop_last=False,\n",
    "                   num_workers=NWORKERS)\n",
    "\n",
    "TEST = DataLoader(dataset=dataset_test,\n",
    "                   batch_size=32,\n",
    "                   shuffle=True,\n",
    "                   drop_last=False,\n",
    "                   num_workers=NWORKERS)\n",
    "\n",
    "VALID = DataLoader(dataset=dataset_valid,\n",
    "                   batch_size=32,\n",
    "                   shuffle=True,\n",
    "                   drop_last=False,\n",
    "                   num_workers=NWORKERS)\n",
    "\n",
    "for i,(x,t) in enumerate(TRAIN):\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python388jvsc74a57bd0e3990d490db936c7f457b709f17e384cb7fd06b3a290a46cb490fc9d9a140231",
   "display_name": "Python 3.8.8 64-bit ('ECOG': conda)"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}